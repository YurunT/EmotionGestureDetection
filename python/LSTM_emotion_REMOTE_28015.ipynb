{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model for Emotion Detection on labeled CMU Panoptic dataset\n",
    "The LSTM model has 30 states in this script, corresponding to the 30 frames within one second.\n",
    "\n",
    "## Input\n",
    "trainX : 3-d array with shape: (# of seconds in total, # of frames/states, dimension of features)\n",
    "\n",
    "e.g. in office1 should be (5346,30,76)\n",
    "\n",
    "trainy : 1-d array with shape: (# of seconds in total,1)\n",
    "\n",
    "## Output\n",
    "\n",
    "Evaluation metrics and runtime spent on fitting\n",
    "\n",
    "## Multipule persons\n",
    "Notice, the LSTM model here is only for single person. \n",
    "The task for multiple person detection is conducted by openpose.\n",
    "\n",
    "So, in the training stage, even if there are multiple persons in one sequence, we split them apart and train the LSTM respectively. \n",
    "Different persons' skeletons are a kind of data augmentation here.\n",
    "\n",
    "While in the demo stage, we will assign each person emerging in the camera one LSTM. \n",
    "\n",
    "## Questions left\n",
    "Why there are 2 persons in office2? Person 2's frames count is 1211?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LET'S GO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from datetime import datetime\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define function for preparing the X and y for LSTM training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### X \n",
    "type: np.ndarray\n",
    "shape: (# of samples, fps, 76)\n",
    "\n",
    "### y \n",
    "type: list\n",
    "shape: (# of samples,1)\n",
    "\n",
    "The calibrated skeletons for each person are stored in :\n",
    "../170915_office1/camerawise_skeleton/hd_0_0(0-30)_samples_for_persons.json\n",
    "\n",
    "'''\n",
    "def prepare_X_y(label_name,data_path,seq_name):\n",
    "    \n",
    "\n",
    "    # Load the skeletons from different cameras\n",
    "    cameras_skeletons_list=list()\n",
    "    json_files = [pos_json for pos_json in os.listdir(data_path+seq_name+\"/camerawise_skeleton/\") if pos_json.endswith('.json')]\n",
    "\n",
    "    for index, js in enumerate(json_files):\n",
    "        try:\n",
    "            with open(os.path.join(data_path+seq_name+\"/camerawise_skeleton/\", js)) as json_file:\n",
    "                skeletons = json.load(json_file)\n",
    "            cameras_skeletons_list.append(skeletons)\n",
    "        except IOError as e:\n",
    "            print('Error reading {0}\\n'.format(skel_json_fname)+e.strerror) \n",
    "    \n",
    "#     print(\"# of cameras:\",len(cameras_skeletons_list))\n",
    "    \n",
    "    # Load the labels\n",
    "    df = pd.read_excel (data_path+seq_name+label_name)\n",
    "    labels=df.as_matrix()# (68,2) ndarray\n",
    "    threshold=34\n",
    "    # threshold deal with no big enough # of skeletons frames\n",
    "    # threshold=argmax(seconds[i]<floor(len(skeletons)/fps)-1)\n",
    "    if label_name=='/office1_label.xlsx':\n",
    "        threshold=63\n",
    "    else:\n",
    "#         threshold=34\n",
    "        threshold=14\n",
    "        \n",
    "    seconds=list(labels[:,0])[0:threshold]# extract all the useful seconds\n",
    "    emotion_label=labels[:,1][0:threshold]# extract all the useful labels\n",
    "\n",
    "    \n",
    "    # Convert the seconds into the frame indexes, the transform equation is: frames=30*seconds + frame\n",
    "    frames_indices=list()\n",
    "    for second in seconds:\n",
    "        for inner_second_frame in range(fps):\n",
    "            frames_indices.append(fps*second+inner_second_frame)\n",
    "\n",
    "    # Filter the seconds(samples) that only appear in the labels\n",
    "    person_trainX=dict()\n",
    "    for skeletons in cameras_skeletons_list:#31 cameras\n",
    "        for person, skels in skeletons.items():\n",
    "            filtered_skels=list()\n",
    "            for i in range(len(skels)):# go over all the frames and match the frame that are interested\n",
    "                if i in frames_indices:\n",
    "                    filtered_skels.append(skels[i])\n",
    "            if person not in person_trainX.keys():\n",
    "                person_trainX[person]=list()\n",
    "                \n",
    "                person_trainX[person].extend(filtered_skels)\n",
    "            else:\n",
    "                person_trainX[person].extend(filtered_skels)\n",
    "\n",
    "    # Convert the skeletons list into ndarray         \n",
    "    for person, samples in person_trainX.items():\n",
    "        # person_trainX[person] store the X\n",
    "        if person=='0':\n",
    "            person_trainX[person]=np.array(person_trainX[person]).reshape((-1,fps,76))\n",
    "\n",
    "    # Extend emotion labels for 31 cameras \n",
    "    y_list=list()\n",
    "    [y_list.extend(emotion_label) for i in range(31)]\n",
    "\n",
    "\n",
    "\n",
    "    # Get the X and y for next step\n",
    "    X=person_trainX['0']\n",
    "    # of samples = 31 * len(frames_indices)\n",
    "#     y=to_categorical(np.array(y_list))# keras one-hot classification label vector\n",
    "    \n",
    "    return X,y_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define function for 10-fold Cross-Validation for LSTM\n",
    "**1)** We will define the model as having a single LSTM hidden layer.\n",
    "\n",
    "LSTM(hidden_nodes, input_shape=(timesteps, input_dim))\n",
    "\n",
    "hidden_nodes = This is the number of neurons of the LSTM. \n",
    "If you have a higher number, the network gets more powerful. \n",
    "Howevery, the number of parameters to learn also rises. \n",
    "This means it needs more time to train the network.\n",
    "\n",
    "timesteps = the number of timesteps you want to consider. \n",
    "E.g. if you want to classify a sentence, this would be the number of words in a sentence.\n",
    "\n",
    "input_dim = the dimensions of your features/embeddings. \n",
    "E.g. a vector representation of the words in the sentence\n",
    "\n",
    "**2)** This is followed by a dropout layer intended to reduce overfitting of the model to the training data.\n",
    "\n",
    "**3)** Finally, a dense fully connected layer is used to interpret the features extracted by the LSTM hidden layer, before a final output layer is used to make predictions.\n",
    "\n",
    "**4)** The efficient Adam version of stochastic gradient descent will be used to optimize the network, and the categorical cross entropy loss function will be used given that we are learning a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LSTM_cv(folds,verbose, epochs, batch_size,X,y_list,y,level_2_dirname_acc,level_2_dirname_loss):    \n",
    "    print(\"Start Cross Validation\")\n",
    "    # Define 10-fold cross validation test harness\n",
    "    seed=7\n",
    "    kfold = StratifiedKFold(folds, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    cvtime=[]\n",
    "    n_timesteps, n_features, n_outputs = X.shape[1], X.shape[2], y.shape[1]\n",
    "    cv=1\n",
    "    show_model = True\n",
    "    # 10 Fold CV for LSTM\n",
    "#     print(X.shape)\n",
    "#     print(\"Start kfold\")\n",
    "    misclassification_skeletons_indices_whole_dataset_folds=list()\n",
    "    mis_pred_res_folds=list()\n",
    "    for train, test in kfold.split(X, y_list):    \n",
    "        # LSTM model\n",
    "        # The output for the model will be a three-element vector containing the probability of a given second belonging to each of the three emotion types.\n",
    "        model = Sequential()\n",
    "        model.add(CuDNNLSTM(78, \n",
    "                       return_sequences=True, \n",
    "                       input_shape=(n_timesteps,n_features)))\n",
    "#         model.add(Dropout(0.2))\n",
    "#         model.add(CuDNNLSTM(50, return_sequences=True))\n",
    "        model.add(Dropout(0.08))\n",
    "        model.add(CuDNNLSTM(58, return_sequences=True))\n",
    "        model.add(Dropout(0.08))\n",
    "        model.add(CuDNNLSTM(58))\n",
    "        model.add(Dropout(0.08))\n",
    "        model.add(Dense(58, activation='relu'))\n",
    "        model.add(Dense(28, activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        optimizer=Adam(lr=8e-5)\n",
    "#         optimizer=Adam(lr=0.00000888, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#         optimizer=SGD(lr=0.00588)\n",
    "        if show_model:\n",
    "            print(model.summary())\n",
    "            show_model = False\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "#         print(\"compiled the model\")\n",
    "        # fit network\n",
    "        t0 = time()\n",
    "        print(\"started fitting\")\n",
    "        history=model.fit(X[train], to_categorical(np.array(y_list)[train]),validation_split=0.33, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "#         print(\"finished fitting\")\n",
    "        t1 = time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(\"started eval\")\n",
    "        # evaluate model\n",
    "        scores = model.evaluate(X[test], to_categorical(np.array(y_list)[test]), batch_size=batch_size, verbose=verbose)\n",
    "#         print(\"finished eval\")\n",
    "                      \n",
    "        # list all data in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        plt.savefig(level_2_dirname_acc+\"/fold\"+str(cv)+'.png')\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        plt.savefig(level_2_dirname_loss+\"/fold\"+str(cv)+'.png')\n",
    "        \n",
    "        \n",
    "        print(\"score from evaluate: %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))# model.metrics_names only have loss and acc\n",
    "        \n",
    "#       incorrects = np.nonzero(model.predict_classes(X[test]) != np.array(y_list)[test])\n",
    "        pred_res = model.predict_classes(X[test])\n",
    "        \n",
    "        unravel_classification_true_false=pred_res==np.array(y_list)[test]\n",
    "        unravel_classification_1_0=unravel_classification_true_false.astype(int)\n",
    "        misclassification_indices=np.where(unravel_classification_1_0==0)[0]\n",
    "        mis_pred_res=pred_res[misclassification_indices]\n",
    "#         misclassification_skeletons=X[test][misclassification_indices]\n",
    "        \n",
    "        misclassification_skeletons_indices_whole_dataset=test[misclassification_indices]\n",
    "        misclassification_skeletons_indices_whole_dataset_folds.append(misclassification_skeletons_indices_whole_dataset)\n",
    "        mis_pred_res_folds.append(mis_pred_res)\n",
    "        \n",
    "        \n",
    "#         set_trace()\n",
    "#         print(\"misclassification vec:\")\n",
    "#         print(unravel_classification_1_0)\n",
    "        print(\"score from predict_class vec:\", sum(unravel_classification_1_0)/len(unravel_classification_1_0))         \n",
    "        \n",
    "        cvscores.append(scores[1] * 100)\n",
    "        cvtime.append(t1-t0)\n",
    "        cv+=1\n",
    "    return cvscores,cvtime,misclassification_skeletons_indices_whole_dataset_folds,mis_pred_res_folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define function for project misclassification skeletons into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skeletons(seconds_indices,mis_pred_res,X,y,level_2_dirname_FS,fold):\n",
    "    X_mistakes=X[seconds_indices]\n",
    "    y_mistakes=y[seconds_indices]\n",
    "    body_edges = np.array([[1,2],[1,4],[4,5],\n",
    "                           [5,6],[1,3],[3,7],\n",
    "                           [7,8],[8,9],[3,13],\n",
    "                           [13,14],[14,15],[1,10],\n",
    "                           [10,11],[11,12]])-1\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.view_init(elev = -90, azim=-90)\n",
    "#     ax.set_xlabel('X Label')\n",
    "#     ax.set_ylabel('Y Label')\n",
    "#     ax.set_zlabel('Z Label')\n",
    "#     ax.axis('equal')\n",
    "#     ax.set_aspect('equal')\n",
    "    fold_path=level_2_dirname_FS+\"/fold\"+str(fold)\n",
    "    if not os.path.exists(fold_path):\n",
    "                os.makedirs(fold_path)\n",
    "    for i, skels in enumerate(X_mistakes):\n",
    "        sec=seconds_indices[i]\n",
    "        true_label=y_mistakes[i]\n",
    "        pred_label=mis_pred_res[i]\n",
    "        print(\"second order: \", sec)\n",
    "        print(\"misclassify label %d into %d\" % (true_label,  pred_label))\n",
    "        if i>2:\n",
    "            break\n",
    "        path_png=fold_path+\"/sec\"+str(sec)+\"_label\"+str(true_label)+\"_into\"+str(pred_label)\n",
    "        for frame, skel in enumerate(skels): #30 consecutive frames\n",
    "#             if frame>2:\n",
    "#                 break\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax = fig.gca(projection='3d')\n",
    "#                     ax.view_init(elev = -90, azim=-90)\n",
    "            ax.set_xlabel('X Label')\n",
    "            ax.set_ylabel('Y Label')\n",
    "            ax.set_zlabel('Z Label')\n",
    "            skel = skel.reshape((-1,4)).transpose()\n",
    "\n",
    "            for j,edge in enumerate(body_edges):\n",
    "                ax.plot(skel[0,edge], skel[2,edge], -skel[1,edge])\n",
    "            \n",
    "            if not os.path.exists(path_png):\n",
    "                os.makedirs(path_png)\n",
    "            \n",
    "            plt.savefig(path_png+\"/frame\"+str(frame)+\".png\")\n",
    "                    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Start LSTM !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ytian/LSTM_with_office1_2/python\n",
      "Tue Nov  5 16:55:49 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:17:00.0 Off |                  N/A |\n",
      "| 34%   32C    P8    17W / 257W |     44MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:65:00.0 Off |                  N/A |\n",
      "| 51%   46C    P8    17W / 257W |      1MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1380      G   /usr/lib/xorg/Xorg                            28MiB |\n",
      "|    0      1525      G   /usr/bin/gnome-shell                          14MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "  anan\u001b[m\n",
      "* \u001b[32mfailure_cases\u001b[m\n",
      "  master\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!nvidia-smi\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up experiment parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "folds,verbose, epochs, batch_size=10,0,100000,500\n",
    "\n",
    "label_num=3\n",
    "\n",
    "matplotlib_interaction_mode=0 # set this to 0 if you want background running\n",
    "if matplotlib_interaction_mode==0:\n",
    "    # Turn interactive plotting off\n",
    "    plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell makes dir to save the reult for every run on distinct timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time:\n",
      "2019 / 11 / 5\n",
      "16 : 50 : 14 . 144265\n",
      "Experiment No. 2019y11m5d16h50m14s\n",
      "3 Labels Classification Task on Skeleton Emotion Detection\n",
      "Hyperparameters Setting: Folds 10 , Verbose 0, Epochs 100000, Batch_Size 500\n",
      "results/2019y11m5d16h50m14s_3classes_10folds_100000epochs_500batchsize\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# get the start timestep for this experiment\n",
    "dateTimeObj = datetime.now()\n",
    "print(\"Current Time:\")\n",
    "print(dateTimeObj.year, '/', dateTimeObj.month, '/', dateTimeObj.day)\n",
    "print(dateTimeObj.hour, ':', dateTimeObj.minute, ':', dateTimeObj.second, '.', dateTimeObj.microsecond)\n",
    "timestamp=str(dateTimeObj.year)+'y'+str(dateTimeObj.month)+\"m\"+str(dateTimeObj.day)+\"d\"+str(dateTimeObj.hour)+\"h\"+str(dateTimeObj.minute)+\"m\"+str(dateTimeObj.second)+\"s\"\n",
    "print(\"Experiment No.\",timestamp)\n",
    "print(\"PID:\",os.getpid())\n",
    "\n",
    "print(\"%d Labels Classification Task on Skeleton Emotion Detection\" % (label_num))\n",
    "print(\"Hyperparameters Setting: Folds %d , Verbose %d, Epochs %d, Batch_Size %d\" % (folds,verbose, epochs, batch_size))\n",
    "\n",
    "\n",
    "\n",
    "level_1_dirname=\"results/\"+timestamp+\"_\"+str(label_num)+\"classes\"+\"_\"+str(folds)+\"folds\"+\"_\"+str(epochs)+\"epochs\"+\"_\"+str(batch_size)+\"batchsize\"\n",
    "level_2_dirname_acc=level_1_dirname+\"/accuracy\"\n",
    "level_2_dirname_loss=level_1_dirname+\"/loss\"\n",
    "level_2_dirname_FS=level_1_dirname+\"/FailedSkeletons\"\n",
    "print(level_1_dirname)\n",
    "\n",
    "print (os.path.exists(level_1_dirname))\n",
    "\n",
    "if not os.path.exists(level_1_dirname):\n",
    "    os.makedirs(level_1_dirname)\n",
    "    os.makedirs(level_2_dirname_acc)\n",
    "    os.makedirs(level_2_dirname_loss)\n",
    "    os.makedirs(level_2_dirname_FS)\n",
    "else:\n",
    "    if not os.path.exists(level_2_dirname_acc):\n",
    "        os.makedirs(level_2_dirname_acc)\n",
    "    if not os.path.exists(level_2_dirname_loss):\n",
    "        os.makedirs(level_2_dirname_loss)\n",
    "    if not os.path.exists(level_2_dirname_FS):\n",
    "        os.makedirs(level_2_dirname_FS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell setups the paths for reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "data_path = '../'\n",
    "seq_name_1 = '170915_office1'#5376 samples in total\n",
    "seq_name_2 = '170407_office2' #3649\n",
    "label_name_office1= '/office1_label.xlsx'\n",
    "label_name_office2= '/office2_label.xlsx'\n",
    "\n",
    "camera_name='0' #could be 0-30\n",
    "# hd_skel_json_path=data_path+seq_name+\"/camerawise_skeleton/\"\n",
    "fps=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell reads the datasets from office1 and office2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the datasets from office1 and office2 \n",
    "\n",
    "# X1,y1_list=prepare_X_y(label_name_office1,data_path,seq_name_1)\n",
    "# X2,y2_list=prepare_X_y(label_name_office2,data_path,seq_name_2)\n",
    "\n",
    "# # Conbine office1 and office2\n",
    "# X=np.concatenate((X1, X2), axis=0)\n",
    "# y1_list.extend(y2_list)\n",
    "# y=to_categorical(np.array(y1_list))# keras one-hot classification label vector\n",
    "\n",
    "# def convert(o):\n",
    "#     if isinstance(o, np.int64): return int(o)  \n",
    "#     raise TypeError\n",
    "# np.save('X.npy',X)\n",
    "# np.save('y.npy',y)\n",
    "# with open('y1_list.json', 'w+') as outfile:\n",
    "#     json.dump(y1_list, outfile,default=convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell performs training and evaluation on LSTM by cross-validation \n",
    "\n",
    "Notice:\n",
    "\n",
    "the \"seconds\" in \"misclassification_seconds_indices_whole_dataset_folds\" still not the real video's second\n",
    "\n",
    "it's only the indices of X and y\n",
    "\n",
    "still need work to map them back to the real timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cross Validation\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 30, 78)            48672     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 78)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 30, 58)            32016     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 58)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 58)                27376     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 58)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                3422      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                1652      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 232       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 113,397\n",
      "Trainable params: 113,397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "started fitting\n",
      "WARNING:tensorflow:From /home/ytian/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-71eec6a7df44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Start trainning and testing LSTM and get results back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcvscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcvtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmisclassification_seconds_indices_whole_dataset_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmis_pred_res_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel_2_dirname_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel_2_dirname_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Try to see which one is misclassified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-751e871635b5>\u001b[0m in \u001b[0;36mLSTM_cv\u001b[0;34m(folds, verbose, epochs, batch_size, X, y_list, y, level_2_dirname_acc, level_2_dirname_loss)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"started fitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m#         print(\"finished fitting\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytianpy36gpu/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the dataset we want\n",
    "X=np.load('X.npy')\n",
    "y=np.load('y.npy')\n",
    "y1 = np.array([yi[1:] for yi in y])\n",
    "with open('y1_list.json') as infile:\n",
    "    y1_list=json.load(infile)\n",
    "y1_list = np.array(y1_list) - 1\n",
    "\n",
    "\n",
    "# Start trainning and testing LSTM and get results back\n",
    "cvscores,cvtime,misclassification_seconds_indices_whole_dataset_folds,mis_pred_res_folds=LSTM_cv(folds,verbose, epochs, batch_size,X,y1_list,y1,level_2_dirname_acc,level_2_dirname_loss)\n",
    "\n",
    "# Try to see which one is misclassified\n",
    "for i, each_fold_misclassification_seconds in enumerate(misclassification_seconds_indices_whole_dataset_folds):\n",
    "    print(\"misclassification skeletons for fold:\", i)\n",
    "    draw_skeletons(each_fold_misclassification_seconds,mis_pred_res_folds[i],X,y1_list,level_2_dirname_FS,i)\n",
    "\n",
    "\n",
    "# Print out the result to console\n",
    "print(\"Average accuracy over %d folds:\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"Average time spent on fitting for each cv with epoch= % d, batchsize= % d is: % 8f seconds\" % (epochs,batch_size,np.mean(cvtime)))\n",
    "\n",
    "# Print out the result to txt\n",
    "sample = open(level_1_dirname+'/avg_result_over_all_folds.txt', 'w+') \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)), file = sample) \n",
    "print(\"average time spent on fitting for each cv with epoch= % d, batchsize= % d is: % .8f seconds\" % (epochs,batch_size,np.mean(cvtime)), file = sample)\n",
    "sample.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 (ytianpy36gpu)",
   "language": "python",
   "name": "ytianpy36gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
